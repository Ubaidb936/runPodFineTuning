{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e119e71a-f88a-4d5c-90fb-e60b84c4f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "import gradio as gr\n",
    "\n",
    "d_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
    "local_model_path = \"outputs/checkpoint-20\"     # Path to the combined weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c2e33e-4e5c-47c4-9516-c7c6a287a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba591ab9-5029-46e8-b9a9-428de3896e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38dc672f62e40b1b875f143c346277e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f55d777e784b4397d381a364fcabb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6ae05624e74c778efbc70b666fc2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae4a13a8aa948b0b7afa4be2b8e5d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e28fd837314dfeb19b54c721b0c2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce084de3874403d99e2b0044350a80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62adab3706e744d49a299b8fbf50816d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the base Model\n",
    "config = PeftConfig.from_pretrained(local_model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path, \n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map=d_map,\n",
    "    # trust_remote_code=True\n",
    ")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d36c14-0bfc-4215-8576-bb390a3a6114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.embed_tokens.weight, Parameter Shape: torch.Size([32000, 4096])\n",
      "Layer: model.layers.0.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.0.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.0.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.0.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.0.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.0.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.0.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.0.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.0.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.1.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.1.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.1.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.1.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.1.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.1.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.1.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.1.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.1.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.2.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.2.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.2.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.2.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.2.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.2.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.2.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.2.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.2.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.3.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.3.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.3.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.3.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.3.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.3.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.3.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.3.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.3.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.4.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.4.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.4.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.4.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.4.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.4.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.4.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.4.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.4.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.5.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.5.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.5.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.5.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.5.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.5.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.5.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.5.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.5.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.6.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.6.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.6.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.6.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.6.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.6.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.6.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.6.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.6.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.7.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.7.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.7.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.7.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.7.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.7.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.7.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.7.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.7.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.8.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.8.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.8.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.8.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.8.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.8.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.8.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.8.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.8.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.9.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.9.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.9.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.9.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.9.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.9.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.9.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.9.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.9.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.10.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.10.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.10.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.10.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.10.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.10.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.10.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.10.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.10.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.11.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.11.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.11.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.11.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.11.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.11.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.11.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.11.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.11.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.12.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.12.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.12.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.12.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.12.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.12.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.12.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.12.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.12.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.13.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.13.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.13.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.13.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.13.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.13.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.13.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.13.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.13.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.14.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.14.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.14.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.14.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.14.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.14.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.14.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.14.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.14.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.15.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.15.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.15.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.15.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.15.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.15.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.15.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.15.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.15.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.16.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.16.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.16.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.16.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.16.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.16.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.16.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.16.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.16.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.17.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.17.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.17.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.17.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.17.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.17.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.17.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.17.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.17.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.18.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.18.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.18.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.18.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.18.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.18.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.18.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.18.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.18.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.19.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.19.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.19.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.19.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.19.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.19.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.19.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.19.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.19.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.20.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.20.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.20.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.20.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.20.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.20.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.20.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.20.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.20.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.21.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.21.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.21.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.21.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.21.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.21.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.21.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.21.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.21.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.22.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.22.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.22.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.22.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.22.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.22.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.22.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.22.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.22.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.23.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.23.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.23.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.23.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.23.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.23.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.23.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.23.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.23.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.24.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.24.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.24.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.24.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.24.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.24.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.24.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.24.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.24.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.25.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.25.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.25.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.25.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.25.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.25.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.25.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.25.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.25.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.26.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.26.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.26.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.26.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.26.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.26.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.26.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.26.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.26.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.27.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.27.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.27.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.27.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.27.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.27.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.27.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.27.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.27.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.28.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.28.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.28.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.28.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.28.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.28.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.28.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.28.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.28.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.29.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.29.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.29.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.29.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.29.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.29.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.29.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.29.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.29.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.30.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.30.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.30.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.30.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.30.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.30.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.30.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.30.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.30.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.31.self_attn.q_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.31.self_attn.k_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.31.self_attn.v_proj.weight, Parameter Shape: torch.Size([1024, 4096])\n",
      "Layer: model.layers.31.self_attn.o_proj.weight, Parameter Shape: torch.Size([4096, 4096])\n",
      "Layer: model.layers.31.mlp.gate_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.31.mlp.up_proj.weight, Parameter Shape: torch.Size([14336, 4096])\n",
      "Layer: model.layers.31.mlp.down_proj.weight, Parameter Shape: torch.Size([4096, 14336])\n",
      "Layer: model.layers.31.input_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.layers.31.post_attention_layernorm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: model.norm.weight, Parameter Shape: torch.Size([4096])\n",
      "Layer: lm_head.weight, Parameter Shape: torch.Size([32000, 4096])\n"
     ]
    }
   ],
   "source": [
    "# # load the base model with the Lora model\n",
    "# model = PeftModel.from_pretrained(model, local_model_path)\n",
    "# mergedModel = model.merge_and_unload()\n",
    "# # mergedModel.eval()\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name}, Parameter Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09fa4575-0dec-4e62-a43f-77e57f68c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferance(query: str, model, tokenizer, temp = 1.0, limit = 200) -> str:\n",
    "  device = \"cuda:0\"\n",
    "\n",
    "  prompt_template = \"\"\"\n",
    "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "  ### Question:\n",
    "  {query}\n",
    "\n",
    "  ### Answer:\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=int(limit), temperature=temp, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  decoded = tokenizer.batch_decode(generated_ids)\n",
    "  return (decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba47700b-0787-4677-a5a1-c1a1b4063fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://7443cd2e64f1b47d4c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7443cd2e64f1b47d4c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(temp, limit, text):\n",
    "    prompt = text\n",
    "    out = inferance(prompt, mergedModel, tokenizer, temp = 1.0, limit = 200)\n",
    "    return out\n",
    "\n",
    "pred = gr.Interface(\n",
    "    predict,\n",
    "    inputs=[\n",
    "        gr.Slider(0.001, 10, value=0.1, label=\"Temperature\"),\n",
    "        gr.Slider(1, 1024, value=128, label=\"Token Limit\"),\n",
    "        gr.Textbox(\n",
    "            label=\"Input\",\n",
    "            lines=1,\n",
    "            value=\"#### Human: What's the capital of Australia?#### Assistant: \",\n",
    "        ),\n",
    "    ],\n",
    "    outputs='text',\n",
    ")\n",
    "\n",
    "pred.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e25a85a-5276-47ff-996d-ddb426eafac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bece25-22f4-4489-a5e8-10a1c28aeae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441a29ce1fd14a259d8538497f16798a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/709 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c38be620174f12b1c13f1794c29b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d955c0a3620242978f507e27ddebf41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"gbharti/finance-alpaca\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2b2ac8-f6ce-40ff-b785-d79e8e673aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': \"This is definitely a scam. I had a friend sign up for a very similar offer and what they did was send a fake check and then asked to transfer the same amount to them. So now you just send them a couple grand and you're holding a fake check.\",\n",
       " 'text': '',\n",
       " 'instruction': 'What risks are there acting as a broker between PayPal and electronic bank transfers?',\n",
       " 'input': ''}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac6e2f-d6eb-4311-95da-082bd92145c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
